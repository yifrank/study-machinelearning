#获取数据
#从sklearn.datasets导入iris数据加载器
from sklearn.datasets import load_iris
#使用加载器读取数据并且存入变量iris。
iris = load_iris()
#查验数据规模
print(iris.data.shape)
#查看数据说明
print(iris.DESCR)

#数据分割
#从sklearn.model_selection里选择导入train_test_split用于数据分割
from sklearn.model_selection import train_test_split
#从使用train_test_split,利用随机种子random_state采样25%的数据作为测试集。
x_train,x_test,y_train,y_test = train_test_split(iris.data,iris.target,test_size=0.25,random_state=33)

#类别预测
#从sklearn.preprocessing里选择导入数据标准化模块
from sklearn.preprocessing import StandardScaler
#从sklearn.neighors里选择导入KNeigborsClassifier,即k近邻分类器。
from sklearn.neighbors import KNeighborsClassifier
#对训练课测试样本进行标准化
ss = StandardScaler()
x_train = ss.fit_transform(x_train)
x_test = ss.transform(x_test)
#使用k近邻分类器对测试数据进行类别预测，预测结果储存在变量y_predict中。
knc = KNeighborsClassifier()
knc.fit(x_train,y_train)
y_predict = knc.predict(x_test)

#性能评估
print(knc.score(x_test,y_test))
from sklearn.metrics import classification_report
print(classification_report(y_test,y_predict,target_names=iris.target_names))

特点分析：
k近邻算法模型没有参数训练的过程。也就是说，我们没有通过任何学习算法分析训练数据，
而只是根据测试样本在训练数据的分布直接做出分类决策。因此，k近邻属于无参数模型中非常简单一种。人儿
正是这样的决策算法，导致了其非常高的计算复杂度和内存消耗。因为该模型每处理一个测试样本，
都需要对所有预先加载在内存的训练样本进行遍历、逐一计算相似度、排序并且选取k个最近邻训练样本
的标记，进而做出分类决策。这是平方级别的算法复杂度，一旦数据规模稍大，使用者便需要权衡更多
计算时间的代价。
